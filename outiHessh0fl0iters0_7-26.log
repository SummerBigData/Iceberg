Using TensorFlow backend.
/users/PAS1383/osu10171/.conda/envs/local/lib/python2.7/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
You have chosen: Namespace(flip=0, h=0, iters=0)
 
2018-07-27 12:50:33.295193: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-07-27 12:50:33.295513: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
Train on 1203 samples, validate on 401 samples
Epoch 1/70
88s - loss: 1.4686 - acc: 0.5004 - val_loss: 0.6912 - val_acc: 0.5137
Epoch 2/70
87s - loss: 0.6884 - acc: 0.5295 - val_loss: 0.6857 - val_acc: 0.5586
Epoch 3/70
86s - loss: 0.6876 - acc: 0.5337 - val_loss: 0.6190 - val_acc: 0.6135
Epoch 4/70
86s - loss: 0.6001 - acc: 0.6093 - val_loss: 0.5735 - val_acc: 0.6608
Epoch 5/70
86s - loss: 0.5731 - acc: 0.6658 - val_loss: 0.5585 - val_acc: 0.6683
Epoch 6/70
86s - loss: 0.6724 - acc: 0.5653 - val_loss: 0.6695 - val_acc: 0.5761
Epoch 7/70
86s - loss: 0.6515 - acc: 0.5611 - val_loss: 0.5965 - val_acc: 0.6534
Epoch 8/70
87s - loss: 0.5969 - acc: 0.5694 - val_loss: 0.5725 - val_acc: 0.6683
Epoch 9/70
87s - loss: 0.5672 - acc: 0.6534 - val_loss: 0.5616 - val_acc: 0.6608
Epoch 10/70
86s - loss: 0.5659 - acc: 0.6642 - val_loss: 0.5718 - val_acc: 0.6758
Epoch 11/70
86s - loss: 0.5533 - acc: 0.6800 - val_loss: 0.5555 - val_acc: 0.6858
Epoch 12/70
86s - loss: 0.5479 - acc: 0.6883 - val_loss: 0.5491 - val_acc: 0.6783
Epoch 13/70
86s - loss: 0.5419 - acc: 0.6833 - val_loss: 0.5405 - val_acc: 0.6858
Epoch 14/70
86s - loss: 0.5451 - acc: 0.6924 - val_loss: 0.5407 - val_acc: 0.6883
Epoch 15/70
86s - loss: 0.5428 - acc: 0.6916 - val_loss: 0.5221 - val_acc: 0.7007
Epoch 16/70
86s - loss: 0.5369 - acc: 0.7024 - val_loss: 0.5164 - val_acc: 0.7107
Epoch 17/70
86s - loss: 0.5241 - acc: 0.7290 - val_loss: 0.5100 - val_acc: 0.7207
Epoch 18/70
86s - loss: 0.5308 - acc: 0.7016 - val_loss: 0.5099 - val_acc: 0.7107
Epoch 19/70
86s - loss: 0.5126 - acc: 0.7390 - val_loss: 0.4816 - val_acc: 0.7506
Epoch 20/70
86s - loss: 0.4860 - acc: 0.7423 - val_loss: 0.5015 - val_acc: 0.7307
Epoch 21/70
87s - loss: 0.5138 - acc: 0.7498 - val_loss: 0.4745 - val_acc: 0.7581
Epoch 22/70
86s - loss: 0.4871 - acc: 0.7440 - val_loss: 0.4472 - val_acc: 0.7880
Epoch 23/70
86s - loss: 0.4569 - acc: 0.7772 - val_loss: 0.4578 - val_acc: 0.7581
Epoch 24/70
86s - loss: 0.4629 - acc: 0.7664 - val_loss: 0.4250 - val_acc: 0.8030
Epoch 25/70
86s - loss: 0.4606 - acc: 0.7822 - val_loss: 0.4164 - val_acc: 0.7980
Epoch 26/70
86s - loss: 0.3998 - acc: 0.8096 - val_loss: 0.4223 - val_acc: 0.7905
Epoch 27/70
86s - loss: 0.3902 - acc: 0.8213 - val_loss: 0.4614 - val_acc: 0.7531
Epoch 28/70
86s - loss: 0.4911 - acc: 0.7606 - val_loss: 0.5223 - val_acc: 0.7681
Epoch 29/70
86s - loss: 0.4982 - acc: 0.7573 - val_loss: 0.4172 - val_acc: 0.7880
Epoch 30/70
86s - loss: 0.4077 - acc: 0.8047 - val_loss: 0.4365 - val_acc: 0.7781
Epoch 31/70
86s - loss: 0.4188 - acc: 0.7947 - val_loss: 0.3993 - val_acc: 0.8030
Epoch 32/70
86s - loss: 0.3795 - acc: 0.8254 - val_loss: 0.4010 - val_acc: 0.8105
Epoch 33/70
85s - loss: 0.3594 - acc: 0.8246 - val_loss: 0.4838 - val_acc: 0.7756
Epoch 34/70
85s - loss: 0.3640 - acc: 0.8288 - val_loss: 0.4669 - val_acc: 0.7756
Epoch 35/70
85s - loss: 0.3968 - acc: 0.8213 - val_loss: 0.4442 - val_acc: 0.7681
Epoch 36/70
85s - loss: 0.3614 - acc: 0.8346 - val_loss: 0.4059 - val_acc: 0.8155
Epoch 37/70
85s - loss: 0.3771 - acc: 0.8213 - val_loss: 0.3760 - val_acc: 0.8155
Epoch 38/70
85s - loss: 0.3417 - acc: 0.8329 - val_loss: 0.3798 - val_acc: 0.8005
Epoch 39/70
86s - loss: 0.3331 - acc: 0.8313 - val_loss: 0.3707 - val_acc: 0.8254
Epoch 40/70
85s - loss: 0.3121 - acc: 0.8595 - val_loss: 0.3539 - val_acc: 0.8304
Epoch 41/70
85s - loss: 0.4034 - acc: 0.8180 - val_loss: 0.3834 - val_acc: 0.8130
Epoch 42/70
85s - loss: 0.3474 - acc: 0.8421 - val_loss: 0.5640 - val_acc: 0.7731
Epoch 43/70
85s - loss: 0.3749 - acc: 0.8379 - val_loss: 0.3653 - val_acc: 0.8180
Epoch 44/70
86s - loss: 0.3165 - acc: 0.8387 - val_loss: 0.3443 - val_acc: 0.8304
Epoch 45/70
85s - loss: 0.3017 - acc: 0.8603 - val_loss: 0.3474 - val_acc: 0.8329
Epoch 46/70
86s - loss: 0.3426 - acc: 0.8221 - val_loss: 0.4185 - val_acc: 0.7756
Epoch 47/70
86s - loss: 0.3006 - acc: 0.8520 - val_loss: 0.3357 - val_acc: 0.8379
Epoch 48/70
85s - loss: 0.2968 - acc: 0.8595 - val_loss: 0.3550 - val_acc: 0.8354
Epoch 49/70
85s - loss: 0.2690 - acc: 0.8878 - val_loss: 0.6058 - val_acc: 0.7805
Epoch 50/70
85s - loss: 0.3935 - acc: 0.8254 - val_loss: 0.3736 - val_acc: 0.8204
Epoch 51/70
85s - loss: 0.3312 - acc: 0.8446 - val_loss: 0.3530 - val_acc: 0.8254
Epoch 52/70
85s - loss: 0.3419 - acc: 0.8362 - val_loss: 0.3598 - val_acc: 0.8379
Epoch 53/70
85s - loss: 0.2927 - acc: 0.8703 - val_loss: 0.3647 - val_acc: 0.8304
Epoch 54/70
85s - loss: 0.2663 - acc: 0.8828 - val_loss: 0.3762 - val_acc: 0.8204
Epoch 55/70
85s - loss: 0.2822 - acc: 0.8720 - val_loss: 0.3251 - val_acc: 0.8404
Epoch 56/70
85s - loss: 0.2778 - acc: 0.8728 - val_loss: 0.3798 - val_acc: 0.8279
Epoch 57/70
85s - loss: 0.2633 - acc: 0.8745 - val_loss: 0.3110 - val_acc: 0.8404
Epoch 58/70
85s - loss: 0.2620 - acc: 0.8753 - val_loss: 0.3789 - val_acc: 0.8080
Epoch 59/70
85s - loss: 0.3537 - acc: 0.8346 - val_loss: 0.3310 - val_acc: 0.8354
Epoch 60/70
85s - loss: 0.3020 - acc: 0.8554 - val_loss: 0.3244 - val_acc: 0.8454
Epoch 61/70
86s - loss: 0.3121 - acc: 0.8595 - val_loss: 0.3576 - val_acc: 0.8254
Epoch 62/70
85s - loss: 0.3109 - acc: 0.8313 - val_loss: 0.3156 - val_acc: 0.8379
Epoch 63/70
85s - loss: 0.3017 - acc: 0.8512 - val_loss: 0.3113 - val_acc: 0.8304
Epoch 64/70
85s - loss: 0.2960 - acc: 0.8570 - val_loss: 0.3195 - val_acc: 0.8479
Epoch 65/70
85s - loss: 0.2803 - acc: 0.8603 - val_loss: 0.3355 - val_acc: 0.8479
Epoch 66/70
85s - loss: 0.2816 - acc: 0.8645 - val_loss: 0.3401 - val_acc: 0.8504
Epoch 67/70
85s - loss: 0.2948 - acc: 0.8579 - val_loss: 0.3365 - val_acc: 0.8429
Epoch 68/70
85s - loss: 0.2527 - acc: 0.8778 - val_loss: 0.3263 - val_acc: 0.8429
Epoch 69/70
85s - loss: 0.2397 - acc: 0.8928 - val_loss: 0.3399 - val_acc: 0.8354
Epoch 70/70
85s - loss: 0.2477 - acc: 0.8745 - val_loss: 0.4132 - val_acc: 0.8155
Training percent for iter
Traceback (most recent call last):
  File "iceunsup2.py", line 217, in <module>
    print 'Training percent for iter', g.iter, 'is', scores[ 0, 1]*100, 'with log loss', scores[ 0, 0]
AttributeError: 'Namespace' object has no attribute 'iter'
